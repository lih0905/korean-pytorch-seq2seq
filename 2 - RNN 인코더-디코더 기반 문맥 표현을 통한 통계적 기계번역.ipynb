{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ben Trevett 의 [Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation](https://github.com/bentrevett/pytorch-seq2seq/blob/master/2%20-%20Learning%20Phrase%20Representations%20using%20RNN%20Encoder-Decoder%20for%20Statistical%20Machine%20Translation.ipynb) 튜토리얼을 한글 데이터셋에 적용해보는 연습이다. 데이터셋은 AI Hub 한국어-영어 번역 말뭉치를 이용한다.\n",
    "\n",
    "이 모델에서는 [Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation](https://arxiv.org/abs/1406.1078) 논문에서 제시한 구조대로 seq2seq 모델을 구현한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 개요\n",
    "\n",
    "일반적은 인코더-디코더 모델의 구조는 다음과 같다.\n",
    "\n",
    "![enc-dec](https://github.com/bentrevett/pytorch-seq2seq/raw/d876a1dcacd7aeeeeeaff2c9b806d23116df048f/assets/seq2seq1.png)\n",
    "\n",
    "직전에 다룬 모델에서는 다음과 같은 다층 LSTM을 이용했다.\n",
    "\n",
    "![LSTM](https://github.com/bentrevett/pytorch-seq2seq/raw/d876a1dcacd7aeeeeeaff2c9b806d23116df048f/assets/seq2seq4.png)\n",
    "\n",
    "LSTM 모델의 단점은 디코더가 hidden states에 너무 많은 정보를 저장해야 한다는 것이다. 따라서 이 정보의 부담을 조금 줄여줌으로서 기존 모델을 개선해보고자 한다. 그리고 여기선 LSTM 대신 GRU를 써보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 전처리\n",
    "\n",
    "저번이랑 비슷함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchtext.data import Field, BucketIterator, TabularDataset\n",
    "\n",
    "import spacy\n",
    "from konlpy.tag import Mecab\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "랜덤 시드를 고정하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "토크나이저를 지정하자. 여기서 한글은 [KoNLPy](https://konlpy-ko.readthedocs.io/ko/v0.4.3/)의 은전한닢, 영어는 [spaCy](https://spacy.io/)를 이용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mecab = Mecab() # 한글\n",
    "spacy_en = spacy.load('en') # 영어"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "토크나이저 함수를 만들자. 이전과는 달리 걍 원래의 순서대로 토큰화한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_ko(text):\n",
    "    return [tok for tok in mecab.morphs(text)]\n",
    "\n",
    "def tokenize_en(text):\n",
    "    return [tok.text for tok in spacy_en.tokenizer(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['한글', '은', '너무', '어렵', '당', '!']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize_ko('한글은 너무 어렵당!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Korean', 'is', 'too', 'dificult', 'for', 'me', '!']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize_en('Korean is too dificult for me!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TorchText의 `Field`를 이용해서 데이터 입력 포맷을 지정하자. `init_token`과 `eos_token` 인자를 이용해서 문장 처음과 마지막에 `<sos>`와 `<eos>` 토큰을 자동으로 추가할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC = Field(tokenize = tokenize_ko,\n",
    "           init_token = '<sos>',\n",
    "           eos_token = '<eos>',\n",
    "           )\n",
    "\n",
    "TRG = Field(tokenize = tokenize_en,\n",
    "            init_token = '<sos>',\n",
    "            eos_token = '<eos>',\n",
    "            lower = True\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = {'ko': ('src',SRC), 'en': ('trg',TRG)}\n",
    "# dictionary 형식은 {csv컬럼명 : (데이터 컬럼명, Field이름)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = TabularDataset.splits(\n",
    "                            path = 'data',\n",
    "                            train = 'train_data.csv',\n",
    "                            test = 'test_data.csv',\n",
    "                            format = 'csv',\n",
    "                            fields = fields,  \n",
    ")\n",
    "valid_data = TabularDataset(path = 'data/valid_data.csv',\n",
    "                            format = 'csv',\n",
    "                            fields = fields,  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "불러온 데이터는 다음과 같은 형태이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'src': ['선생', '님', '이', '문장', '이', '이해', '가', '안', '가', '요', '.'],\n",
       "  'trg': ['sir',\n",
       "   ',',\n",
       "   'i',\n",
       "   'do',\n",
       "   \"n't\",\n",
       "   'understand',\n",
       "   'this',\n",
       "   'sentence',\n",
       "   'here',\n",
       "   '.']},\n",
       " {'src': ['학교', '가', '끝나', '자마자', '기숙사', '로', '가요', '.'],\n",
       "  'trg': ['i',\n",
       "   'go',\n",
       "   'to',\n",
       "   'dormitory',\n",
       "   'as',\n",
       "   'soon',\n",
       "   'as',\n",
       "   'i',\n",
       "   'finished',\n",
       "   'class',\n",
       "   '.']})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(train_data[0]), vars(valid_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 단어장을 만들자. `min_freq` 옵션을 이용하여 최소 2번 이상 등장하는 단어만 사용하도록 하자. 또한 단어장은 검증/테스트셋은 써서는 안된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC.build_vocab(train_data, min_freq=2)\n",
    "TRG.build_vocab(train_data, min_freq=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이터레이터를 만들자. 일반적인 `Iterator` 대신 `BucketIterator` 쓰면 입력/출력 배치 안에 있는 문장의 길이가 최대한 비슷하게 되어 패딩을 최소화하게 해준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data),\n",
    "    batch_size = BATCH_SIZE,\n",
    "    sort_key = lambda x: len(x.src),\n",
    "    sort_within_batch = True,\n",
    "    device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 64])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_iterator)).src.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seq2seq 모델 생성\n",
    "\n",
    "## 인코더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
