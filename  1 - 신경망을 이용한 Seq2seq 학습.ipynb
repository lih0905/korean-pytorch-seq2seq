{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ben Trevett 의 [Sequence to Sequence Learning with Neural Networks](https://github.com/bentrevett/pytorch-seq2seq/blob/master/1%20-%20Sequence%20to%20Sequence%20Learning%20with%20Neural%20Networks.ipynb) 튜토리얼을 한글 데이터셋에 적용해보는 연습이다. 데이터셋은 [AI Hub 한국어-영어 번역 말뭉치](http://www.aihub.or.kr/aidata/87/download)를 이용한다.\n",
    "\n",
    "이 모델에서는 [Sequence to Sequence Learning with Neural Networks](https://arxiv.org/abs/1409.3215) 논문에서 제시한 구조대로 간단한 모델을 만들어본다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 개요\n",
    "\n",
    "가장 유명한 seq2seq 모델은 RNN을 이용한 인코더-디코더 모델이다. 입력 문장은 인코더를 통해 하나의 문맥 벡터로 변환되고, 이후 디코더에서 타겟 문장으로 변환된다.\n",
    "\n",
    "![seq2seq](https://github.com/bentrevett/pytorch-seq2seq/raw/49cbdd39d934633ab69b7ff0cf4ef0da33a42e18/assets/seq2seq1.png)\n",
    "\n",
    "문장의 처음에 `<sos>`, 마지막에 `<eos>` 토큰을 추가하여 입력으로 넣는다. 입력 문장의 각 단어 $x_t$에 대해 벡터 임베딩을 $e(x_t)$, 이전 타임의 히든 벡터를 $h_{t-1}$ 이라 하면 인코더는 다음과 같이 정의된다.\n",
    "\n",
    "$$ h_t = \\text{EncoderRNN}(e(X_t), h_{t-1}) $$\n",
    "\n",
    "여기서 $X = \\{ x_1,\\ldots, x_T\\}$, $x_1 = <sos>$ 등이다. 마지막 단어에 대한 히든 벡터 $h_T$를 문장의 벡터로 정의한다.\n",
    "\n",
    "디코더는 타겟 문장 $(y_t)$의 임베딩 $d(y_t)$와 이전 히든 벡터 $s_{t-1}$에 대해 다음과 같이 정의된다($s_0 = h_T$).\n",
    "\n",
    "$$ s_t = \\text{DecoderRNN}(d(y_t), s_{t-1}) $$\n",
    "\n",
    "마지막으로 디코더의 출력을 선형 레이어 $f$에 태워 각 단어의 최종 스코어 $\\hat{y}_t = f(s_t)$ 를 만든다. 타겟 문장의 입력은 항상 `<sos>` 토큰으로 시작하지만, 그 이후의 벡터는 실제 타겟 단어 $y_t$를 입력을 넣을 수도 있고 아니면 이전 단계의 출력 $\\hat{y}_t$를 넣을 수도 있다. \n",
    "\n",
    "이렇게 얻은 타겟 벡터 $\\hat{Y} = \\{ \\hat{y}_1, \\ldots, \\hat{y}_T\\}$ 를 실제 정답과 비교하여 손실을 계산하고 모델을 업데이트한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 전처리\n",
    "\n",
    "이후 사용할 모듈들을 불러오자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchtext.data import Field, BucketIterator, TabularDataset\n",
    "\n",
    "import spacy\n",
    "from konlpy.tag import Mecab\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "랜덤 시드를 고정하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "토크나이저를 지정하자. 여기서 한글은 [KoNLPy](https://konlpy-ko.readthedocs.io/ko/v0.4.3/)의 은전한닢, 영어는 [spaCy](https://spacy.io/)를 이용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mecab = Mecab() # 한글\n",
    "spacy_en = spacy.load('en') # 영어"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "토크나이저 함수를 만들자. 논문에 따르면 입력 문장은 역순으로 넣는 게 좋다고 하니 그대로 따르자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_ko(text):\n",
    "    return [tok for tok in mecab.morphs(text)][::-1]\n",
    "\n",
    "def tokenize_en(text):\n",
    "    return [tok.text for tok in spacy_en.tokenizer(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['!', '당', '어렵', '너무', '은', '한글']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize_ko('한글은 너무 어렵당!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Korean', 'is', 'too', 'dificult', 'for', 'me', '!']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize_en('Korean is too dificult for me!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TorchText의 `Field`를 이용해서 데이터 입력 포맷을 지정하자. `init_token`과 `eos_token` 인자를 이용해서 문장 처음과 마지막에 `<sos>`와 `<eos>` 토큰을 자동으로 추가할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC = Field(tokenize = tokenize_ko,\n",
    "           init_token = '<sos>',\n",
    "           eos_token = '<eos>',\n",
    "           )\n",
    "\n",
    "TRG = Field(tokenize = tokenize_en,\n",
    "            init_token = '<sos>',\n",
    "            eos_token = '<eos>',\n",
    "            lower = True\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = {'ko': ('src',SRC), 'en': ('trg',TRG)}\n",
    "# dictionary 형식은 {csv컬럼명 : (데이터 컬럼명, Field이름)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.구어체.xlsx  3.문어체-뉴스.xlsx  train_data.csv\n",
      "2.대화체.xlsx  test_data.csv\t   valid_data.csv\n"
     ]
    }
   ],
   "source": [
    "!ls data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = TabularDataset.splits(\n",
    "                            path = 'data',\n",
    "                            train = 'train_data.csv',\n",
    "                            test = 'test_data.csv',\n",
    "                            format = 'csv',\n",
    "                            fields = fields,  \n",
    ")\n",
    "valid_data = TabularDataset(path = 'data/valid_data.csv',\n",
    "                            format = 'csv',\n",
    "                            fields = fields,  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "불러온 데이터는 다음과 같은 형태이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'src': ['.', '요', '가', '안', '가', '이해', '이', '문장', '이', '님', '선생'],\n",
       "  'trg': ['sir',\n",
       "   ',',\n",
       "   'i',\n",
       "   'do',\n",
       "   \"n't\",\n",
       "   'understand',\n",
       "   'this',\n",
       "   'sentence',\n",
       "   'here',\n",
       "   '.']},\n",
       " {'src': ['.', '가요', '로', '기숙사', '자마자', '끝나', '가', '학교'],\n",
       "  'trg': ['i',\n",
       "   'go',\n",
       "   'to',\n",
       "   'dormitory',\n",
       "   'as',\n",
       "   'soon',\n",
       "   'as',\n",
       "   'i',\n",
       "   'finished',\n",
       "   'class',\n",
       "   '.']})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(train_data[0]), vars(valid_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "길이를 확인해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 94463\n",
      "Number of validation examples: 31688\n",
      "Number of testing examples: 31822\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of training examples: {len(train_data.examples)}\")\n",
    "print(f\"Number of validation examples: {len(valid_data.examples)}\")\n",
    "print(f\"Number of testing examples: {len(test_data.examples)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 단어장을 만들자. `min_freq` 옵션을 이용하여 최소 2번 이상 등장하는 단어만 사용하도록 하자. 또한 단어장은 검증/테스트셋은 써서는 안된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC.build_vocab(train_data, min_freq=2)\n",
    "TRG.build_vocab(train_data, min_freq=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in source (ko) vocabulary: 33345\n",
      "Unique tokens in target (en) vocabulary: 24619\n"
     ]
    }
   ],
   "source": [
    "print(f\"Unique tokens in source (ko) vocabulary: {len(SRC.vocab)}\")\n",
    "print(f\"Unique tokens in target (en) vocabulary: {len(TRG.vocab)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이터레이터를 만들자. 일반적인 `Iterator` 대신 `BucketIterator` 쓰면 입력/출력 배치 안에 있는 문장의 길이가 최대한 비슷하게 되어 패딩을 최소화하게 해준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data),\n",
    "    batch_size = BATCH_SIZE,\n",
    "    sort_key = lambda x: len(x.src),\n",
    "    sort_within_batch = True,\n",
    "    device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 32])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_iterator)).src.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seq2seq 모델 생성\n",
    "\n",
    "인코더, 디코더, 그리고 seq2seq 모델 순서대로 만들자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 인코더\n",
    "\n",
    "인코더는 2레이어 LSTM을 사용하여 다음과 같이 정의한다.\n",
    "\n",
    "$$ (h_t^1,c_t^1)= \\text{EncoderLSTM}^1(e(x_t),(h_{t-1}^1,c_{t-1}^1)) $$\n",
    "\n",
    "$$ (h_t^2,c_t^2)= \\text{EncoderLSTM}^2(h_t^1,(h_{t-1}^2, c_{t-1}^2)) $$\n",
    "\n",
    "![encoder](https://github.com/bentrevett/pytorch-seq2seq/raw/49cbdd39d934633ab69b7ff0cf4ef0da33a42e18/assets/seq2seq2.png)\n",
    "\n",
    "인코더는 다음 인수들을 입력으로 받는다.\n",
    "\n",
    "* `input_dim` : 입력 문장의 단어 갯수\n",
    "* `emb_dim` : 임베딩 차원\n",
    "* `hid_dim` : 히든 차원\n",
    "* `n_layers` : RNN 계층수\n",
    "* `dropout` : dropout 비율. 계층 사이에 적용된다.\n",
    "\n",
    "출력은 `outputs`(최상위층 히든 벡터), `hidden`(각 층별 최종 히든 state를 쌓음), `cell`(각 층별 셀 state를 쌓은 벡터) 이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, hid_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout=dropout)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, src):\n",
    "        # src = [src_len, batch_size]\n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        \n",
    "        # embedded = [src_len, batch_size, emb_dim]\n",
    "        outputs, (hidden, cell) = self.rnn(embedded)\n",
    "        \n",
    "        # outputs = [src_len, batch_size, hid_dim * n_direction]\n",
    "        #print(\"outputs shape : {}\".format(outputs.shape))\n",
    "        # hidden = [n_layers * n_direction, batch_size, hid_dim]\n",
    "        #print(\"hidden shape : {}\".format(hidden.shape))\n",
    "        # cell = [n_layers * n_direction, batch_size, hid_dim]\n",
    "        #print(\"cell shape : {}\".format(cell.shape))\n",
    "        \n",
    "        return hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.1226,  0.0346,  0.1716,  ...,  0.4877,  0.3778, -0.2108],\n",
       "          [ 0.2642, -0.0190, -0.0653,  ...,  0.2019,  0.2856, -0.0675],\n",
       "          [ 0.2633, -0.0312, -0.0503,  ..., -0.2938, -0.3479,  0.0081],\n",
       "          ...,\n",
       "          [ 0.0144,  0.1000,  0.1812,  ..., -0.0714, -0.3423, -0.0349],\n",
       "          [ 0.0831,  0.0031, -0.2627,  ..., -0.4309,  0.4981, -0.1830],\n",
       "          [ 0.0435,  0.0219,  0.0047,  ..., -0.3588,  0.4724, -0.1527]],\n",
       " \n",
       "         [[-0.0057, -0.0647,  0.0599,  ..., -0.0166, -0.0216,  0.1694],\n",
       "          [-0.0576, -0.0393,  0.1705,  ..., -0.0051,  0.0441,  0.1316],\n",
       "          [-0.1214, -0.0838,  0.0903,  ...,  0.0542,  0.0354, -0.0320],\n",
       "          ...,\n",
       "          [-0.0762, -0.1770,  0.2006,  ...,  0.1002,  0.0772,  0.0884],\n",
       "          [-0.0114, -0.0913,  0.1388,  ...,  0.1078,  0.0263,  0.0884],\n",
       "          [-0.0319, -0.1424,  0.1051,  ...,  0.0573,  0.0237,  0.1356]]],\n",
       "        device='cuda:0', grad_fn=<CudnnRnnBackward>),\n",
       " tensor([[[ 0.3097,  0.1161,  0.2274,  ...,  0.7434,  0.5003, -0.4151],\n",
       "          [ 0.6458, -0.1091, -0.1686,  ...,  0.3670,  0.3488, -0.1893],\n",
       "          [ 0.5496, -0.1326, -0.1061,  ..., -0.3727, -0.5190,  0.0137],\n",
       "          ...,\n",
       "          [ 0.0413,  0.1786,  0.5972,  ..., -0.1313, -0.4548, -0.0676],\n",
       "          [ 0.1237,  0.0760, -0.5412,  ..., -0.5774,  0.6285, -0.2570],\n",
       "          [ 0.0676,  0.1558,  0.0065,  ..., -0.5723,  0.5920, -0.3663]],\n",
       " \n",
       "         [[-0.0110, -0.1333,  0.1328,  ..., -0.0385, -0.0458,  0.2920],\n",
       "          [-0.1212, -0.0693,  0.3585,  ..., -0.0101,  0.0942,  0.2298],\n",
       "          [-0.2215, -0.1484,  0.1770,  ...,  0.1031,  0.0717, -0.0627],\n",
       "          ...,\n",
       "          [-0.1695, -0.2942,  0.4173,  ...,  0.1908,  0.1454,  0.1953],\n",
       "          [-0.0236, -0.1898,  0.2946,  ...,  0.2134,  0.0563,  0.1679],\n",
       "          [-0.0591, -0.2667,  0.2101,  ...,  0.1334,  0.0430,  0.2796]]],\n",
       "        device='cuda:0', grad_fn=<CudnnRnnBackward>))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src = next(iter(train_iterator))\n",
    "enc = Encoder(len(SRC.vocab), 200, 100, 2, 0.5)\n",
    "enc.to('cuda')\n",
    "enc(src.src)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 디코더\n",
    "\n",
    "디코더는 2층 LSTM 이며 다음 그림과 같은 구조를 가진다.\n",
    "\n",
    "![decoder](https://github.com/bentrevett/pytorch-seq2seq/raw/6559ece8dcb41d2cb9cfe479c7442c8d6c0d90bb/assets/seq2seq3.png)\n",
    "\n",
    "$$ (s_t^1,c_t^1)= \\text{DecoderLSTM}^1(d(y_t),(s_{t-1}^1,c_{t-1}^1)) $$\n",
    "\n",
    "$$ (s_t^2,c_t^2)= \\text{DecoderLSTM}^2(s_t^1,(s_{t-1}^2, c_{t-1}^2)) $$\n",
    "\n",
    "초기값은 인코더의 출력으로 다음과 같이 정의된다.\n",
    "\n",
    "$$ (s_0^l, c_0^l) = z^l = (h_T^l, c_T^l) $$\n",
    "\n",
    "가장 윗층의 히든 스테이트 $s_t^L$를 선형 계층 $f$에 통과시켜 다음 토큰의 예측값 $\\hat{y}_{t+1}$을 얻는다.\n",
    "\n",
    "순전파 과정에서 디코더는 한번에 하나씩의 토큰만 처리한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, hid_dim , n_layers, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.output_dim = output_dim\n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout=dropout)\n",
    "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, input, hidden, cell):\n",
    "        # input = [batch_size]\n",
    "        # hidden = [n_layers * n_direction, batch_size, hid_dim]\n",
    "        # cell = [n_layers * n_direction, batch_size, hid_dim]\n",
    "        \n",
    "        input = input.unsqueeze(0)\n",
    "        # input = [1, batch_size]\n",
    "        \n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        # embedded = [1, batch_size, emb_dim]\n",
    "        \n",
    "        output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n",
    "        # output = [1, batch size, hid dim * n directions]\n",
    "        # hidden = [n layers * n directions, batch size, hid dim]\n",
    "        # cell = [n layers * n directions, batch size, hid dim]\n",
    "        \n",
    "        prediction = self.fc_out(output.squeeze(0))\n",
    "        # prediction = [batch_size, output_dim]\n",
    "        \n",
    "        return prediction, hidden, cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seq2seq\n",
    "\n",
    "다음을 수행하는 seq2seq 모델을 만들자.\n",
    "\n",
    "* 원 문장을 입력으로 받고\n",
    "* 인코더를 이용하여 문맥 벡터를 만든 후\n",
    "* 디코더를 이용하여 결과 문장을 예측한다.\n",
    "\n",
    "![seq2seq](https://github.com/bentrevett/pytorch-seq2seq/raw/6559ece8dcb41d2cb9cfe479c7442c8d6c0d90bb/assets/seq2seq4.png)\n",
    "\n",
    "순전파 과정에서 원 문장과 타겟 문장과 `teacher-forcing rate`를 입력으로 받는다. `teacher-forcing rate`는 훈련 과정에서 다음 토큰의 입력을 실제 타겟 문장의 토큰으로 할지, 아니면 이전 토큰의 결과값으로 할지 비율을 결정한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "        \n",
    "        assert encoder.hid_dim == decoder.hid_dim, \\\n",
    "        \"Hidden dimensions of encoder and decoder must be equal!\"\n",
    "        assert encoder.n_layers == decoder.n_layers, \\\n",
    "        \"Encoder and decoder must have equal number of layers!\"\n",
    "        \n",
    "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
    "        \"\"\"\n",
    "        src = [src_len, batch_size]\n",
    "        trg = [trg_len, batch_size]\n",
    "        \"\"\"\n",
    "        \n",
    "        batch_size = trg.shape[1]\n",
    "        trg_len = trg.shape[0]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "        \n",
    "        # 디코더 출력값을 저장할 텐서\n",
    "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
    "        \n",
    "        # 인코더의 마지막 히든 스테이트는 디코더의 최초 히든 스테이트\n",
    "        hidden, cell = self.encoder(src)\n",
    "        \n",
    "        # 디코더의 입력의 처음은 <sos> 토큰\n",
    "        input = trg[0,:]\n",
    "        \n",
    "        for t in range(1, trg_len):\n",
    "            # 인풋 토큰, 이전 히든/셀 스테이트를 입력으로 넣고\n",
    "            # 아웃풋 텐서, 새로운 히든/셀 스테이트를 출력\n",
    "            output, hidden, cell = self.decoder(input, hidden, cell)\n",
    "            \n",
    "            # outputs에 저장 (output = [batch_size, output_dim])\n",
    "            outputs[t] = output\n",
    "            \n",
    "            # teacher forcing 쓸지 말지\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            \n",
    "            # 출력중 최고값\n",
    "            top1 = output.argmax(1)\n",
    "            \n",
    "            # teacher_forcing=True 이면 groud truth,\n",
    "            # 아니면 이전 예측값을 다음 입력으로 넣음\n",
    "            input = trg[t] if teacher_force else top1\n",
    "            \n",
    "        return outputs\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seq2seq 모델 훈련\n",
    "\n",
    "하이퍼 파라미터들을 정하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(SRC.vocab)\n",
    "OUTPUT_DIM = len(TRG.vocab)\n",
    "ENC_EMB_DIM = 128\n",
    "DEC_EMB_DIM = 128\n",
    "HID_DIM = 256\n",
    "N_LAYERS = 2\n",
    "ENC_DROPOUT = 0.5\n",
    "DEC_DROPOUT = 0.5\n",
    "\n",
    "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
    "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n",
    "\n",
    "model = Seq2Seq(enc, dec, device).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델의 초기값은 $\\mathfrak{U}(-0.08,0.08)$을 따르도록 한다. 이때 `apply` 메서드를 적용하는데, 이 메서드는 입력으로 받은 함수를 각 모듈과 서브모듈에 적용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(33345, 128)\n",
       "    (rnn): LSTM(128, 256, num_layers=2, dropout=0.5)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embedding): Embedding(24619, 128)\n",
       "    (rnn): LSTM(128, 256, num_layers=2, dropout=0.5)\n",
       "    (fc_out): Linear(in_features=256, out_features=24619, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        nn.init.uniform_(param.data, -0.08, 0.08)\n",
    "\n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "파라미터 갯수는?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 15,589,675 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "옵티마이저는 Adam을 쓴다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "손실함수는 `CrossEntropyLoss` 를 쓴다. 다만 `<pad>` 토큰은 무시하도록 `igonre_index` 옵션을 넣어준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=TRG_PAD_IDX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련 과정을 정의하자. 이때 trg 벡터의 첫번째 토큰은 항상 `<sos>` 토큰이고, 이 토큰은 학습시키지 않는다. 이때 주의할 점은 다음과 같다.\n",
    "\n",
    "* 손실 함수는 2차원 입력과 1차원 타겟을 다루게 되어 있으므로 입력을 `view()` 메서드를 이용해서 변환해주어야 한다.\n",
    "* Gradient exploding 현상을 방지하기 위해 gradient clapping을 적용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, clip):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for i, batch in enumerate(iterator):\n",
    "        src = batch.src\n",
    "        trg = batch.trg\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(src, trg)\n",
    "        \n",
    "        # trg = [trg_len, batch_size]\n",
    "        # output = [trg_len, batch_size, output_dim]\n",
    "        output_dim = output.shape[-1]\n",
    "        \n",
    "        output = output[1:].view(-1, output_dim) # <sos> 토큰 제외\n",
    "        trg = trg[1:].view(-1)\n",
    "        \n",
    "        # trg = [(trg_len - 1) * batch_size]\n",
    "        # output = [(trg_len - 1) * batch_size, output_dim]\n",
    "        \n",
    "        loss = criterion(output, trg)\n",
    "        loss.backward()\n",
    "        \n",
    "        # gradient clapping\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        \n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "평가 과정에서는 `teacher_forcing`을 꺼주어야 한다는 점에 주의!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(iterator):\n",
    "            src = batch.src\n",
    "            trg = batch.trg\n",
    "            \n",
    "            output = model(src, trg, 0) # teacher forcing 제거\n",
    "            output_dim = output.shape[-1]\n",
    "            \n",
    "            output = output[1:].view(-1, output_dim)\n",
    "            trg = trg[1:].view(-1)\n",
    "            \n",
    "            loss = criterion(output, trg)\n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련 시간 측정 함수를 만들자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련을 시켜보자. 각 에폭마다 성능이 좋아지면 모델의 파라미터를 저장하도록 한다. 그리고 loss와 perplexity(=exp(loss))를 출력하도록 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 8m 10s\n",
      "\tTrain Loss: 5.726 | Train PPL: 306.708\n",
      "\t Val. Loss: 5.802 |  Val. PPL: 331.111\n",
      "Epoch: 02 | Time: 8m 9s\n",
      "\tTrain Loss: 5.202 | Train PPL: 181.621\n",
      "\t Val. Loss: 5.618 |  Val. PPL: 275.344\n",
      "Epoch: 03 | Time: 8m 9s\n",
      "\tTrain Loss: 4.910 | Train PPL: 135.577\n",
      "\t Val. Loss: 5.420 |  Val. PPL: 225.901\n",
      "Epoch: 04 | Time: 8m 9s\n",
      "\tTrain Loss: 4.685 | Train PPL: 108.261\n",
      "\t Val. Loss: 5.296 |  Val. PPL: 199.561\n",
      "Epoch: 05 | Time: 8m 7s\n",
      "\tTrain Loss: 4.509 | Train PPL:  90.793\n",
      "\t Val. Loss: 5.231 |  Val. PPL: 186.899\n",
      "Epoch: 06 | Time: 8m 10s\n",
      "\tTrain Loss: 4.380 | Train PPL:  79.827\n",
      "\t Val. Loss: 5.167 |  Val. PPL: 175.458\n",
      "Epoch: 07 | Time: 8m 7s\n",
      "\tTrain Loss: 4.265 | Train PPL:  71.140\n",
      "\t Val. Loss: 5.130 |  Val. PPL: 169.061\n",
      "Epoch: 08 | Time: 8m 9s\n",
      "\tTrain Loss: 4.166 | Train PPL:  64.439\n",
      "\t Val. Loss: 5.100 |  Val. PPL: 164.011\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 10\n",
    "CLIP = 1\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
    "    valid_loss = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'tut1-model.pt')\n",
    "        \n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "테스트셋에 확인해보자!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Test Loss: 5.086 | Test PPL: 161.698 |\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('tut1-model.pt'))\n",
    "\n",
    "test_loss = evaluate(model, test_iterator, criterion)\n",
    "\n",
    "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "추가 훈련을 시켜보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 09 | Time: 8m 8s\n",
      "\tTrain Loss: 3.939 | Train PPL:  51.361\n",
      "\t Val. Loss: 5.048 |  Val. PPL: 155.668\n",
      "Epoch: 10 | Time: 8m 8s\n",
      "\tTrain Loss: 3.887 | Train PPL:  48.788\n",
      "\t Val. Loss: 5.027 |  Val. PPL: 152.471\n",
      "Epoch: 11 | Time: 8m 9s\n",
      "\tTrain Loss: 3.835 | Train PPL:  46.285\n",
      "\t Val. Loss: 5.011 |  Val. PPL: 149.985\n",
      "Epoch: 12 | Time: 8m 10s\n",
      "\tTrain Loss: 3.793 | Train PPL:  44.382\n",
      "\t Val. Loss: 5.030 |  Val. PPL: 152.949\n",
      "Epoch: 13 | Time: 8m 7s\n",
      "\tTrain Loss: 3.747 | Train PPL:  42.409\n",
      "\t Val. Loss: 5.002 |  Val. PPL: 148.685\n",
      "Epoch: 14 | Time: 8m 8s\n",
      "\tTrain Loss: 3.711 | Train PPL:  40.881\n",
      "\t Val. Loss: 5.049 |  Val. PPL: 155.944\n",
      "Epoch: 15 | Time: 8m 9s\n",
      "\tTrain Loss: 3.671 | Train PPL:  39.296\n",
      "\t Val. Loss: 5.036 |  Val. PPL: 153.832\n",
      "Epoch: 16 | Time: 8m 11s\n",
      "\tTrain Loss: 3.635 | Train PPL:  37.902\n",
      "\t Val. Loss: 5.025 |  Val. PPL: 152.102\n",
      "Epoch: 17 | Time: 8m 11s\n",
      "\tTrain Loss: 3.602 | Train PPL:  36.675\n",
      "\t Val. Loss: 5.007 |  Val. PPL: 149.517\n",
      "Epoch: 18 | Time: 8m 11s\n",
      "\tTrain Loss: 3.572 | Train PPL:  35.573\n",
      "\t Val. Loss: 5.020 |  Val. PPL: 151.389\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 10\n",
    "CLIP = 1\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
    "    valid_loss = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'tut1-model.pt')\n",
    "        \n",
    "    print(f'Epoch: {epoch+9:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "추론 함수를 구현한 후 실제 번역을 돌려보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(model, sentence):\n",
    "    model.eval()\n",
    "    \n",
    "    # 한글 문장을 역순으로 토크나이징\n",
    "    tokenized = [tok for tok in reversed(mecab.morphs(sentence))]\n",
    "    #print(tokenized)\n",
    "    \n",
    "    # 문장 앞뒤에 <sos>, <eos> 토큰 추가\n",
    "    indexed = [SRC.vocab.stoi[SRC.init_token]]+[SRC.vocab.stoi[t] for t in tokenized]+[SRC.vocab.stoi[SRC.eos_token]]\n",
    "    #print(indexed)\n",
    "    \n",
    "    # LongTensor 변환\n",
    "    tensor = torch.LongTensor(indexed).to(device)\n",
    "    tensor = tensor.unsqueeze(1) # 배치 \n",
    "    #print(tensor)\n",
    "    \n",
    "    # TRG 문장은 처음에만 <sos> 토큰을 넣고 나머진 0 으로 입력\n",
    "    zero_trg = torch.LongTensor([[TRG.vocab.stoi[TRG.init_token]]+[0 for _ in range(100)]]).t().to(device)\n",
    "    #print(zero_trg.shape)\n",
    "    outputs = model(tensor, zero_trg, 0)\n",
    "    \n",
    "    # 모델 출력값으로부터 번역 문장 생성\n",
    "    # <eos> 토큰을 만나면 거기에서 종료\n",
    "    res = []\n",
    "    for i in range(1,outputs.shape[0]):\n",
    "        ind = outputs[i].argmax(1)\n",
    "        if ind == TRG.vocab.stoi[TRG.eos_token]:\n",
    "            break\n",
    "        res.append(TRG.vocab.itos[ind])\n",
    "    return ' '.join(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'do you eat eat rice ?'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentiment(model, '밥은 먹고 다니냐?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"today 's day is clean today .\""
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentiment(model, '오늘 하늘은 하루종일 맑다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"it 's a program that goes to the the .\""
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = \"\"\"\n",
    "생중계에서 모든 과정을 총지휘하는 연출가에 가깝다.\n",
    "\"\"\"\n",
    "predict_sentiment(model, sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the change the the the the the the the the . .'"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = \"\"\"\n",
    "무대에 오르는 배우 숫자에 따라 카메라 수도 변한다. \n",
    "\"\"\"\n",
    "predict_sentiment(model, sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'welcome your best for the health of the health !'"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = \"\"\"\n",
    "전국 곳곳에서 최선을 다해 치료해 주시는 의료진 선생님들 힘내세요 화이팅!!!!\n",
    "\"\"\"\n",
    "predict_sentiment(model, sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i went to the restaurant today .'"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = \"\"\"\n",
    "오늘 결혼식장에 다녀왔다.\n",
    "\"\"\"\n",
    "predict_sentiment(model, sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"it 's too hard to clean your hands !\""
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = \"\"\"\n",
    "청소하기 너무 귀찮아!\n",
    "\"\"\"\n",
    "predict_sentiment(model, sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이걸로는 안되겠다! ㅋㅋㅋ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
